
# DO NOT EDIT THIS FILE - GENERATED FROM 02_ts_utils.ipynb

import tensorflow as tf
import tensorflow.keras as keras
import matplotlib as mpl
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler, MinMaxScaler
import pickle

mpl.rcParams['figure.figsize'] = (14, 4)
mpl.rcParams['axes.grid'] = True

#--------------------------------------------------------------------------------
'''
    Load the data you prepared - you must have run 01_ts_dataprep 
'''
def load_file( file = '../data/jena_climate_2009_2016.csv.zip'):
    df = pd.read_csv(file+".csv")
    df['Date Time'] = pd.to_datetime( df['Date Time'], format='%Y-%m-%d %H:%M:%S' )
    df_scaled_trn   = pd.read_csv(file+".trn.csv")
    df_scaled_tst   = pd.read_csv(file+".tst.csv")
    scaler          = pickle.load(open(f'{file}.scaler.pkl', 'rb'))

    # You can inverse transform predicted value to get original value 
    # pd.DataFrame(scaler.inverse_transform(scaler.transform(df_train)))

    return df, df_scaled_trn, df_scaled_tst, scaler

#--------------------------------------------------------------------------------
'''
    dataset:        must be tf.data.Dataset.from_tensor_slices
    label_slice:    labels (indices or slice(start,end, skip) )
    window_len:     Length of the window
    output_len:     Length of the labels (# of steps to predict)

Usage:
    df = pd.read_csv(file) or [[0,1,2,3], [0,1,2,3], [0,1,2,3], [0,1,2,3], [0,1,2,3]]
    ds = timeseries_dataset_from_dataset(df, 2, 2, slice(0, 2))
    #print_dataset(ds)

'''
def window(dataset, window_len, output_length, label_slice=slice(0,1), batch_size=1, skip = 0 ):
    ds = dataset.window(window_len + skip + output_length, shift=1, drop_remainder=True)
    ds = ds.flat_map(lambda x: x).batch(window_len + skip+ output_length)
     
    def split_feature_label(x):
        return x[:window_len], x[window_len+skip:,label_slice]
     
    ds = ds.map(split_feature_label)

    return ds.batch(batch_size)

#--------------------------------------------------------------------------------
# Compute the Average of the training output and we will use this as default predictions
# Also for computing R-squared value
def compute_avg(window):
    count, total = 0, None;
    for w in window:
        if (not count):
            total = w[1]
        else:
            total += w[1]
        count += 1

    avg_output = total/count
    return avg_output

#--------------------------------------------------------------------------------
'''
    predict the model,
    y:      is the original array of expected 
    yhat:   is the predicted values
'''
def model_predict(model, window, y=None, yhat= None, howmany=1024*1024):
    for w in window.take(howmany):
        xc = w[0]
        yc = w[1]
        yp = model.predict(xc, verbose=0)

        yc = yc[:,-1,:]
        yp = yp[:,-1,:]

        if ( y is None):
            y = yc
            yhat = yp
            continue;
        
        y = np.concatenate([y,yc])
        yhat = np.concatenate([yhat,yp])

    return y, yhat


#--------------------------------------------------------------------------------
# Define inv_transform functions - Note: yh: [batch, time, features length]
def inverse_transform(yh, scaler, label_slice, df=None):
    yy=np.empty([yh.shape[0], scaler.n_features_in_])
    yy[:] = np.nan

    yy[:, label_slice] = yh
    ys = scaler.inverse_transform(yy)

    if (df is not None):
        ys = pd.DataFrame(ys[:, label_slice], columns=df.columns[label_slice])

    return ys    
