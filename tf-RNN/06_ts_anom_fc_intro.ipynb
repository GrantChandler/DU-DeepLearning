{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "XVhK72Pu1cJL"
   },
   "source": [
    "#### Anomaly Detection - Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T02:53:20.699018Z",
     "iopub.status.busy": "2022-12-14T02:53:20.698277Z",
     "iopub.status.idle": "2022-12-14T02:53:23.285398Z",
     "shell.execute_reply": "2022-12-14T02:53:23.284632Z"
    },
    "id": "7rZnJaGTWQw0"
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Lambda, Dropout, SimpleRNN, Dense, LSTM, RepeatVector, Input, TimeDistributed, concatenate\n",
    "from keras import regularizers\n",
    "from keras.utils import plot_model\n",
    "\n",
    "import IPython, IPython.display, os, datetime\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (14, 4)\n",
    "mpl.rcParams['axes.grid'] = True\n",
    "\n",
    "print(f\"Tensorflow Version {tf.__version__}, Keras Vesion: {keras.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ts_utils\n",
    "import ts_plot_utils\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import pickle\n",
    "\n",
    "# STEP 1: = >Lets just read the first few columns for testing\n",
    "df = pd.read_csv(\"../data/processminer-rare-event-mts.csv.zip\", sep=';', usecols=range(59))\n",
    "split = int (.8 * len(df) )\n",
    "df_scaled_trn = df [df.columns[2:] ][0:split ]\n",
    "df_scaled_tst = df [df.columns[2:] ][split: ]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df_scaled_trn = pd.DataFrame(scaler.fit_transform(df_scaled_trn), columns=df_scaled_trn.columns)\n",
    "df_scaled_tst = pd.DataFrame(scaler.transform(df_scaled_tst), columns=df_scaled_tst.columns)\n",
    "\n",
    "\n",
    "#  STEP 2: => Create window\n",
    "\n",
    "input_slice  = slice(0, len(df_scaled_trn.columns) )\n",
    "label_slice  = input_slice\n",
    "window_len   = 5\n",
    "ouput_len    = 1\n",
    "batch_size   = 64\n",
    "\n",
    "inp_feat_len    = input_slice.stop - (input_slice.start or 0)\n",
    "ouput_feat_len  = label_slice.stop - (label_slice.start or 0)\n",
    "\n",
    "ds_trn        = tf.data.Dataset.from_tensor_slices(df_scaled_trn[df_scaled_trn.columns[input_slice]])\n",
    "ds_tst        = tf.data.Dataset.from_tensor_slices(df_scaled_tst[df_scaled_trn.columns[input_slice]])\n",
    "window_trn    = ts_utils.window(ds_trn, window_len, ouput_len, label_slice, batch_size=batch_size,)\n",
    "window_tst    = ts_utils.window(ds_tst, window_len, ouput_len, label_slice, batch_size=batch_size )\n",
    "window_trn100 = ts_utils.window(ds_trn, window_len, ouput_len, label_slice, batch_size=100000  )\n",
    "window_tst100 = ts_utils.window(ds_tst, window_len, ouput_len, label_slice, batch_size=100000  )\n",
    "\n",
    "df_scaled_trn\n",
    "#for w in window_trn.take(1): print(f'{w[0]} \\n\\n {w[1]}' )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "performance = {}\n",
    "models = []\n",
    "\n",
    "# Linear Model\n",
    "linear_model = tf.keras.Sequential([\n",
    "    # Take the last time-step.\n",
    "    # Shape [batch, time, features] => [batch, 1, features]\n",
    "    tf.keras.layers.Lambda(lambda x: x[:, -1:, :])\n",
    "    ] + ts_utils.getCommonLayer(ouput_len, ouput_feat_len),\n",
    "    name = \"Linear\"\n",
    ")\n",
    "models.append(linear_model)\n",
    "ts_utils.compile_fit(models[-1])\n",
    "models[-1].fit(window_trn.take(1), epochs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 256\n",
    "\n",
    "# Create Autoencoder Layer\n",
    "input_layer = Input(shape=(window_len, inp_feat_len), dtype='float32', name='input')\n",
    "memory_layer = LSTM(dim, return_sequences=True)(input_layer)\n",
    "memory_layer = LSTM (dim//2, return_sequences=False)(memory_layer)\n",
    "repeated_lyr = RepeatVector(window_len)(memory_layer)\n",
    "memory_layer = LSTM (dim//2, return_sequences=True)(repeated_lyr)\n",
    "memory_layer = LSTM (dim,  return_sequences=True)(memory_layer)\n",
    "decoded_inputs = TimeDistributed(Dense(units=inp_feat_len, activation='linear'))( memory_layer)\n",
    "\n",
    "dropout_input = Dropout(0.2)(input_layer)\n",
    "concat_layer = concatenate([dropout_input, decoded_inputs])\n",
    "memory_layer = LSTM(units=dim, \n",
    "                    kernel_regularizer = regularizers.l1_l2(l1= 0, l2= 0), \n",
    "                    recurrent_regularizer = regularizers.l1_l2(l1= 0, l2= 0), \n",
    "                    return_sequences=False)(concat_layer)\n",
    "\n",
    "# => Note this is same as getCommonLayer(ouput_len, ouput_feat_len, memory_layer)\n",
    "#\n",
    "preds = Dense(units=ouput_feat_len*ouput_len)(memory_layer)\n",
    "preds = Dense(units=ouput_feat_len*ouput_len, activation='linear')(preds)\n",
    "preds = tf.keras.layers.Reshape([ouput_len, ouput_feat_len])(preds)\n",
    "umodel = Model(input_layer, preds, name=\"Uber\")\n",
    "\n",
    "models.append(umodel)\n",
    "ts_utils.compile_fit(models[-1])\n",
    "models[-1].fit(window_trn.take(1), epochs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umodel.layers[-2].set_weights(linear_model.layers[-2].weights)\n",
    "ts_utils.compile_fit(models[-1])\n",
    "models[-1].fit(window_trn.take(1), epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM Model\n",
    "lstm_model = tf.keras.Sequential([\n",
    "        # Shape [batch, time, features] => [batch, lstm_units].\n",
    "        # Adding more `lstm_units` just overfits more quickly.\n",
    "\n",
    "        tf.keras.layers.LSTM(32, return_sequences=False)\n",
    "    ]+ ts_utils.getCommonLayer(ouput_len, ouput_feat_len),\n",
    "    name = \"LSTM\"\n",
    ")\n",
    "models.append(lstm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%script echo\n",
    "for i, model in enumerate(models):\n",
    "    print(f\"Now Compiling model: {model.name} => {i+1}/{len(models)} models\")\n",
    "    history = ts_utils.compile_fit(model, window_trn, window_tst, epochs=50, patience=3, verbose=1)\n",
    "    IPython.display.clear_output()\n",
    "\n",
    "IPython.display.clear_output()\n",
    "# Plot graphs\n",
    "#performance={}\n",
    "performance = ts_plot_utils.plot_performance(models, window_trn100, window_tst100, performance=performance, reeval=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.clear_output()\n",
    "\n",
    "for l in history.history:\n",
    "    plt.plot(history.history[l], label=f\"{l}\")\n",
    "plt.title(\"History of Losses\")\n",
    "plt.legend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anomaly Score - precision/Recall etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model     = models[0]\n",
    "trn_errdf = None\n",
    "tst_errdf = None\n",
    "\n",
    "def getErrDF(model, window_trn, retdf=None, columns=None):\n",
    "    for w in window_trn:\n",
    "        p = model.predict(w[0])\n",
    "        r = w[1] - p.reshape(w[1].shape)\n",
    "        r.numpy().sum(axis=1)\n",
    "        df=pd.DataFrame(r[:,-1], columns=columns) \n",
    "        \n",
    "        if (retdf is None):\n",
    "            retdf = df\n",
    "        else:\n",
    "            retdf.append(df, ignore_index=1)\n",
    "\n",
    "    return retdf\n",
    "\n",
    "trn_errdf = getErrDF (model, window_trn100, trn_errdf, df_scaled_trn.columns)\n",
    "tst_errdf = getErrDF (model, window_tst100, tst_errdf, df_scaled_trn.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_errdf.hist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "time_series.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "5ef3244febf2748b7299853ebe20fbefab2f9f94ffe70cfaeb9efc5b5372c95d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
