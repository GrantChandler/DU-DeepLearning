{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "XVhK72Pu1cJL"
   },
   "source": [
    "#### Forecasting: Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T02:53:20.699018Z",
     "iopub.status.busy": "2022-12-14T02:53:20.698277Z",
     "iopub.status.idle": "2022-12-14T02:53:23.285398Z",
     "shell.execute_reply": "2022-12-14T02:53:23.284632Z"
    },
    "id": "7rZnJaGTWQw0"
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.callbacks  import EarlyStopping\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Lambda, Dropout, SimpleRNN, Dense, LSTM, RepeatVector, Input, TimeDistributed, concatenate\n",
    "from keras import regularizers\n",
    "\n",
    "import IPython, IPython.display, os, datetime\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ts_utils\n",
    "import ts_plot_utils\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (14, 4)\n",
    "mpl.rcParams['axes.grid'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "df, df_scaled_trn, df_scaled_tst, scaler = ts_utils.load_file()\n",
    "print(\"Training Data:\")\n",
    "display(df_scaled_trn)\n",
    "\n",
    "input_slice  = slice(0, len(df_scaled_trn.columns) )\n",
    "label_slice  = slice(0,3)\n",
    "window_len   = 24\n",
    "ouput_len    = 1\n",
    "batch_size   = 64\n",
    "\n",
    "inp_feat_len    = input_slice.stop - (input_slice.start or 0)\n",
    "ouput_feat_len  = label_slice.stop - (label_slice.start or 0)\n",
    "\n",
    "ds_trn        = tf.data.Dataset.from_tensor_slices(df_scaled_trn[df_scaled_trn.columns[input_slice]])\n",
    "ds_tst        = tf.data.Dataset.from_tensor_slices(df_scaled_tst[df_scaled_trn.columns[input_slice]])\n",
    "window_trn    = ts_utils.window(ds_trn, window_len, ouput_len, label_slice, batch_size=batch_size,)\n",
    "window_tst    = ts_utils.window(ds_tst, window_len, ouput_len, label_slice, batch_size=batch_size )\n",
    "window_trn100 = ts_utils.window(ds_trn, window_len, ouput_len, label_slice, batch_size=100000  )\n",
    "window_tst100 = ts_utils.window(ds_tst, window_len, ouput_len, label_slice, batch_size=100000  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo Skipping - Testing Window -comment this line to test\n",
    "\n",
    "# Check if your window logic is correctly working\n",
    "# Note it will print only the first item in the batch\n",
    "#\n",
    "i =0\n",
    "for w in window_trn.take(i+1):\n",
    "    break;\n",
    "\n",
    "print(f\"Sample a window at index {i} verify the window is working:\\n\")\n",
    "print(f\"{w[0].numpy().shape}\\n{w[0][0].numpy()}\\n=>:{w[1].numpy().shape}\\n{w[1][0].numpy()} \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo Skipping - Inverse transform comment this line to test\n",
    "\n",
    "display(df_scaled_trn[:4])\n",
    "display(df[df.columns[1:]][:4])\n",
    "pd.DataFrame(scaler.inverse_transform(df_scaled_trn[:4].values), columns=df_scaled_trn.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_fit(model, window_trn, window_tst= None, opt=None, patience=3, epochs=1, **kwargs):\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=patience, mode='min', restore_best_weights = True)\n",
    "\n",
    "    loss = tf.keras.losses.MeanSquaredError()\n",
    "    opt  = opt or tf.keras.optimizers.Adam()\n",
    "    mets = [tf.keras.metrics.MeanAbsoluteError()]\n",
    "\n",
    "    ##=> Other options you can try\n",
    "    #learning_rate = 1e-6\n",
    "    #opt = tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.9)\n",
    "    #opt = tf.keras.optimizers.SGD()\n",
    "    #loss=tf.keras.losses.Huber()\n",
    "\n",
    "    model.compile(loss= loss, optimizer= opt, metrics=mets)\n",
    "\n",
    "    history = []\n",
    "    if (window_trn is not None):\n",
    "        history = model.fit(window_trn, epochs=epochs, validation_data=window_tst, \n",
    "                                workers=4, use_multiprocessing=True, callbacks=[early_stop], **kwargs)\n",
    "\n",
    "    return history\n",
    "\n",
    "# This commonLayer, a layer that is common to all models\n",
    "\n",
    "def getCommonLayer(ouput_len, ouput_feat_len):\n",
    "    op_len = ouput_len * ouput_feat_len;\n",
    "    commonLayer = [\n",
    "        # Shape => [batch, 1, out_len * #features]\n",
    "        tf.keras.layers.Dense( op_len, kernel_initializer=tf.initializers.zeros()),\n",
    "        \n",
    "        # Shape => [batch, out_steps, features]\n",
    "        tf.keras.layers.Reshape([ouput_len, ouput_feat_len])\n",
    "    ]\n",
    "    return commonLayer\n",
    "\n",
    "performance = {}\n",
    "models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T03:04:30.807611Z",
     "iopub.status.busy": "2022-12-14T03:04:30.806770Z",
     "iopub.status.idle": "2022-12-14T03:05:37.592821Z",
     "shell.execute_reply": "2022-12-14T03:05:37.592112Z"
    },
    "id": "Bf1ks6RTzF64"
   },
   "outputs": [],
   "source": [
    "# LSTM Model\n",
    "lstm_model = tf.keras.Sequential([\n",
    "        # Shape [batch, time, features] => [batch, lstm_units].\n",
    "        # Adding more `lstm_units` just overfits more quickly.\n",
    "\n",
    "        tf.keras.layers.LSTM(32, return_sequences=False)\n",
    "    ]+ getCommonLayer(ouput_len, ouput_feat_len),\n",
    "    name = \"LSTM\"\n",
    ")\n",
    "models.append(lstm_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T03:02:16.490628Z",
     "iopub.status.busy": "2022-12-14T03:02:16.490367Z",
     "iopub.status.idle": "2022-12-14T03:02:46.815152Z",
     "shell.execute_reply": "2022-12-14T03:02:46.814503Z"
    },
    "id": "kfRz_WVhIQcd"
   },
   "outputs": [],
   "source": [
    "# Linear Model\n",
    "linear_model = tf.keras.Sequential([\n",
    "    # Take the last time-step.\n",
    "    # Shape [batch, time, features] => [batch, 1, features]\n",
    "    tf.keras.layers.Lambda(lambda x: x[:, -1:, :])\n",
    "    ] + getCommonLayer(ouput_len, ouput_feat_len),\n",
    "    name = \"Linear\"\n",
    ")\n",
    "models.append(linear_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple RNN\n",
    "srnn_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.SimpleRNN(40)]\n",
    "    + getCommonLayer(ouput_len, ouput_feat_len)\n",
    "    , name=\"SimpleRNN\")\n",
    "\n",
    "models.append(srnn_model)\n",
    "\n",
    "# Add a Dense Layer\n",
    "dlinear_model = tf.keras.Sequential([\n",
    "        # Take the last time-step.\n",
    "        # Shape [batch, time, features] => [batch, 1, features]\n",
    "        tf.keras.layers.Lambda(lambda x: x[:, -1:, :]),\n",
    "        tf.keras.layers.Dense(512, activation='relu')\n",
    "    ] +  getCommonLayer(ouput_len, ouput_feat_len),\n",
    "    name = \"DenseLinear\"\n",
    ")\n",
    "models.append(dlinear_model)\n",
    "\n",
    "\n",
    "# CNN\n",
    "CONV_WIDTH = 3\n",
    "conv_model = tf.keras.Sequential([\n",
    "    # Shape [batch, time, features] => [batch, CONV_WIDTH, features]\n",
    "    tf.keras.layers.Lambda(lambda x: x[:, -CONV_WIDTH:, :]),\n",
    "    # Shape => [batch, 1, conv_units]\n",
    "    tf.keras.layers.Conv1D(256, activation='relu', kernel_size=(CONV_WIDTH)),\n",
    "    ] + getCommonLayer(ouput_len, ouput_feat_len),\n",
    "    name = \"Conv\"\n",
    ")\n",
    "models.append(conv_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 256\n",
    "\n",
    "# Create Autoencoder Layer\n",
    "input_layer = Input(shape=(window_len, inp_feat_len), dtype='float32', name='input')\n",
    "memory_layer = LSTM(dim, return_sequences=True)(input_layer)\n",
    "memory_layer = LSTM (dim//2, return_sequences=False)(memory_layer)\n",
    "repeated_lyr = RepeatVector(window_len)(memory_layer)\n",
    "memory_layer = LSTM (dim//2, return_sequences=True)(repeated_lyr)\n",
    "memory_layer = LSTM (dim,  return_sequences=True)(memory_layer)\n",
    "decoded_inputs = TimeDistributed(Dense(units=inp_feat_len, activation='linear'))( memory_layer)\n",
    "\n",
    "dropout_input = Dropout(0.2)(input_layer)\n",
    "concat_layer = concatenate([dropout_input, decoded_inputs])\n",
    "memory_layer = LSTM(units=dim, \n",
    "                    kernel_regularizer = regularizers.l1_l2(l1= 0, l2= 0), \n",
    "                    recurrent_regularizer = regularizers.l1_l2(l1= 0, l2= 0), \n",
    "                    return_sequences=False)(concat_layer)\n",
    "\n",
    "# => Note this is same as getCommonLayer(ouput_len, ouput_feat_len, memory_layer)\n",
    "#\n",
    "# preds = Dense(units=ouput_feat_len*ouput_len)(memory_layer)\n",
    "preds = Dense(units=ouput_feat_len*ouput_len, activation='linear')(memory_layer)\n",
    "preds = tf.keras.layers.Reshape([ouput_len, ouput_feat_len])(preds)\n",
    "umodel = Model(input_layer, preds, name=\"Uber\")\n",
    "\n",
    "#models.append(umodel)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile and Evaluate All the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, model in enumerate(models):\n",
    "    print(f\"Now Compiling {i+1}/{len(models)} {model.name} \")\n",
    "    #history = compile_fit(model, window_trn, window_tst, epochs=5, verbose=1)\n",
    "    history = compile_fit(model, None, window_tst, epochs=5, verbose=1)\n",
    "    IPython.display.clear_output()\n",
    "\n",
    "# Plot graphs\n",
    "#performance={}\n",
    "performance = ts_plot_utils.plot_performance(models, window_trn100, window_tst100, performance=performance, reeval=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = umodel\n",
    "ydf, pdf = ts_plot_utils.predict_and_plot( model, window_trn100, window_tst100, howmany=1024* 1024,\n",
    "                        plot_start=-200, df=None, scaler=None, label_slice=None)\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = linear_model\n",
    "ydf, pdf = ts_plot_utils.predict_and_plot( model, window_trn100, window_tst100, howmany=1024* 1024,\n",
    "                        plot_start=-200, df=None, scaler=None, label_slice=None)\n",
    ";"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The END"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "time_series.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "5ef3244febf2748b7299853ebe20fbefab2f9f94ffe70cfaeb9efc5b5372c95d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
