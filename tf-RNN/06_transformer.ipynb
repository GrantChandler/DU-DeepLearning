{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow Version 2.10.0, Keras Vesion: 2.10.0\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import IPython, IPython.display, os, datetime\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.callbacks  import EarlyStopping\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Lambda, Dropout, Input\n",
    "from keras import regularizers\n",
    "from keras.utils import plot_model\n",
    "\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (14, 4)\n",
    "mpl.rcParams['axes.grid'] = True\n",
    "\n",
    "print(f\"Tensorflow Version {tf.__version__}, Keras Vesion: {keras.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%writefile \"transformermodel.py\"\n",
    "\n",
    "# DO NOT EDIT THIS FILE - GENERATED FROM 06_transformer.ipynb\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from keras.layers import Embedding, MultiHeadAttention, LayerNormalization\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    Precomputes a matrix with all the positional encodings \n",
    "\n",
    "    Arguments:\n",
    "        positions (int) -- Maximum number of positions to be encoded \n",
    "        d (int) -- Encoding size \n",
    "\n",
    "    Returns:\n",
    "        pos_encoding -- (1, position, d_model) A matrix with the positional encodings\n",
    "\"\"\"\n",
    "def positional_encoding(positions, d):\n",
    "    # initialize a matrix angle_rads of all the angles \n",
    "    pos = np.arange(positions)[:, np.newaxis] \n",
    "    d = np.float32(d)\n",
    "\n",
    "    angle_rads = pos/ np.power(10000, (2 * (np.arange(d)[np.newaxis, :]//2)) / d)\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "    \n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "    \n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    Creates a matrix mask for the padding cells\n",
    "\n",
    "    Arguments:\n",
    "        decoder_token_ids -- (n, m) matrix\n",
    "\n",
    "    Returns:\n",
    "        mask -- (n, 1, m) binary tensor\n",
    "\"\"\"    \n",
    "def create_padding_mask(decoder_token_ids):\n",
    "    seq = 1 - tf.cast(tf.math.equal(decoder_token_ids, 0), tf.float32)\n",
    "  \n",
    "    # add extra dimensions to add the padding\n",
    "    # to the attention logits.\n",
    "    return seq[:, tf.newaxis, :]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Returns a lower triangular matrix filled with ones\n",
    "\n",
    "Arguments:\n",
    "    sequence_length -- matrix size\n",
    "\n",
    "Returns:\n",
    "    mask -- (size, size) tensor\n",
    "\"\"\"\n",
    "def create_look_ahead_mask(sequence_length):\n",
    "    mask = tf.linalg.band_part(tf.ones((1, sequence_length, sequence_length)), -1, 0)\n",
    "    return mask \n",
    "\n",
    "\n",
    "def FullyConnected(embedding_dim, fully_connected_dim):\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(fully_connected_dim, activation='relu'),  # (batch_size, seq_len, dff)\n",
    "        tf.keras.layers.Dense(embedding_dim)  # (batch_size, seq_len, d_model)\n",
    "    ])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    The encoder layer is composed by a multi-head self-attention mechanism,\n",
    "    followed by a simple, positionwise fully connected feed-forward network. \n",
    "    This archirecture includes a residual connection around each of the two \n",
    "    sub-layers, followed by layer normalization.\n",
    "\"\"\"\n",
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, embedding_dim, num_heads, fully_connected_dim,\n",
    "                 dropout_rate=0.1, layernorm_eps=1e-6):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.mha = MultiHeadAttention(num_heads=num_heads,\n",
    "                                      key_dim=embedding_dim,\n",
    "                                      dropout=dropout_rate)\n",
    "\n",
    "        self.ffn = FullyConnected(embedding_dim=embedding_dim,\n",
    "                                  fully_connected_dim=fully_connected_dim)\n",
    "\n",
    "        self.layernorm1 = LayerNormalization(epsilon=layernorm_eps)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=layernorm_eps)\n",
    "\n",
    "        self.dropout_ffn = Dropout(dropout_rate)\n",
    "    \n",
    "    def call(self, x, training, mask):\n",
    "        \"\"\"\n",
    "        Forward pass for the Encoder Layer\n",
    "        \n",
    "        Arguments:\n",
    "            x -- Tensor of shape (batch_size, input_seq_len, fully_connected_dim)\n",
    "            training -- Boolean, set to true to activate\n",
    "                        the training mode for dropout layers\n",
    "            mask -- Boolean mask to ensure that the padding is not \n",
    "                    treated as part of the input\n",
    "        Returns:\n",
    "            encoder_layer_out -- Tensor of shape (batch_size, input_seq_len, embedding_dim)\n",
    "        \"\"\"\n",
    "        # calculate self-attention using mha(~1 line).\n",
    "        # Dropout is added by Keras automatically if the dropout parameter is non-zero during training\n",
    "        self_mha_output = self.mha(query=x,\n",
    "                                   value=x,\n",
    "                                   key=x,\n",
    "                                   attention_mask=mask,training=training) \n",
    "        # Self attention (batch_size, input_seq_len, \n",
    "        \n",
    "        # skip connection\n",
    "        # apply layer normalization on sum of the input and the attention output to get the  \n",
    "        # output of the multi-head attention layer (~1 line)\n",
    "        skip_x_attention = self.layernorm1( x + self_mha_output)  # (batch_size, input_seq_len, fully_connected_dim)\n",
    "\n",
    "        # pass the output of the multi-head attention layer through a ffn (~1 line)\n",
    "        ffn_output = self.ffn(skip_x_attention)  # (batch_size, input_seq_len, fully_connected_dim)\n",
    "        \n",
    "        # apply dropout layer to ffn output during training (~1 line)\n",
    "        # use `training=training` \n",
    "        ffn_output = self.dropout_ffn(ffn_output, training)\n",
    "        \n",
    "        # apply layer normalization on sum of the output from multi-head attention (skip connection) and ffn output to get the\n",
    "        # output of the encoder layer (~1 line)\n",
    "        encoder_layer_out = self.layernorm2(skip_x_attention + ffn_output)  # (batch_size, input_seq_len, embedding_dim)\n",
    "        \n",
    "        return encoder_layer_out\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "The entire Encoder starts by passing the input to an embedding layer \n",
    "and using positional encoding to then pass the output through a stack of\n",
    "encoder Layers\n",
    "    \n",
    "\"\"\"  \n",
    "class Encoder(tf.keras.layers.Layer):\n",
    "    '''\n",
    "        embedding_dim = send in dimension of the input features for time series\n",
    "        maximum_positions = in case of time series, it is the windows length\n",
    "\n",
    "    '''\n",
    "    def __init__(self,   embedding_dim,\n",
    "                         maximum_position_encoding=1024,\n",
    "                        num_layers = 6, num_heads=3, \n",
    "                        fully_connected_dim=64, input_vocab_size=None,\n",
    "                        dropout_rate=0.1,  layernorm_eps=1e-6,\n",
    "                        task=\"timseries|NLP\"):\n",
    "\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        # Shape is same same (positions, features_len) for time series\n",
    "        self.myinput_shape   = (maximum_position_encoding, embedding_dim)\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.input_vocab_size = input_vocab_size\n",
    "        self.maximum_position_encoding = maximum_position_encoding\n",
    "\n",
    "\n",
    "        self.enc_layers = [EncoderLayer(embedding_dim=self.embedding_dim,\n",
    "                                        num_heads=num_heads,\n",
    "                                        fully_connected_dim=fully_connected_dim,\n",
    "                                        dropout_rate=dropout_rate,\n",
    "                                        layernorm_eps=layernorm_eps) \n",
    "                           for _ in range(self.num_layers)]\n",
    "\n",
    "        self.dropout = Dropout(dropout_rate)\n",
    "        self.task = task\n",
    "        \n",
    "    def embed_timeseries(self, x):\n",
    "        assert self.task != \"NLP\", \"Hmmm calling embed on non timeseries app\"\n",
    "\n",
    "        # For now it is noop\n",
    "        return x\n",
    "\n",
    "    def embed(self, x):\n",
    "        if self.task != \"NLP\":\n",
    "            return self.embed_timeseries(x)\n",
    "\n",
    "        if ( not self.embedding):\n",
    "            self.embedding = Embedding(self.input_vocab_size, self.embedding_dim)\n",
    "        x = self.embedding(x)  # (batch_size, input_seq_len, embedding_dim)\n",
    "\n",
    "        # Scale embedding by multiplying by square root embedding dimension\n",
    "        x *= np.sqrt( self.embedding_dim )\n",
    "        return x\n",
    "                \n",
    "    def positional_encode(self, x):\n",
    "        if self.task != \"NLP\":\n",
    "            return x\n",
    "        if ( not self.pos_encoding):\n",
    "            pe = positional_encoding(self.maximum_position_encoding, \n",
    "                                     self.embedding_dim)\n",
    "            self.pos_encoding = pe\n",
    "\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "        return x\n",
    "\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        x -- Tensor of shape (batch_size, input_seq_len) for NLP\n",
    "                            (batch_size, input_seq_len, features_len) for time series\n",
    "\n",
    "        training -- Boolean, set to true to activate\n",
    "                    the training mode for dropout layers\n",
    "        mask -- Boolean mask to ensure that the padding is not \n",
    "                treated as part of the input\n",
    "    Returns:\n",
    "        out2 -- Tensor of shape (batch_size, input_seq_len, embedding_dim)\n",
    "    \"\"\"\n",
    "    def call(self, x, training = True, mask=None):\n",
    "        # Note followig two lines are noop for time series analysis\n",
    "        x = self.embed(x)\n",
    "        x = self.positional_encode (x)\n",
    "        x = self.dropout(x, training)\n",
    "        # Pass the output through the stack of encoding layers \n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x, training, mask)\n",
    "            #x = self.enc_layers[0](x, training, mask)\n",
    "\n",
    "        return x  # (batch_size, input_seq_len, embedding_dim)\n",
    "\n",
    "    def build(self):\n",
    "        inputs = keras.Input(shape=self.myinput_shape)\n",
    "        output = self.call(inputs)\n",
    "        return inputs, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    '''\n",
    "        output features len \n",
    "    '''\n",
    "    def __init__(self, output_feat_len, output_len = 1\n",
    "                        num_layers = 6, num_heads=3, \n",
    "                        fully_connected_dim=64, input_vocab_size=None,\n",
    "                        dropout_rate=0.1,  layernorm_eps=1e-6,\n",
    "                        task=\"timseries|NLP\"):\n",
    "\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_24 (InputLayer)       [(None, 1024, 2)]         0         \n",
      "                                                                 \n",
      " dropout_145 (Dropout)       (None, 1024, 2)           0         \n",
      "                                                                 \n",
      " encoder_layer_122 (EncoderL  (None, 1024, 2)          398       \n",
      " ayer)                                                           \n",
      "                                                                 \n",
      " encoder_layer_123 (EncoderL  (None, 1024, 2)          398       \n",
      " ayer)                                                           \n",
      "                                                                 \n",
      " encoder_layer_124 (EncoderL  (None, 1024, 2)          398       \n",
      " ayer)                                                           \n",
      "                                                                 \n",
      " encoder_layer_125 (EncoderL  (None, 1024, 2)          398       \n",
      " ayer)                                                           \n",
      "                                                                 \n",
      " encoder_layer_126 (EncoderL  (None, 1024, 2)          398       \n",
      " ayer)                                                           \n",
      "                                                                 \n",
      " encoder_layer_127 (EncoderL  (None, 1024, 2)          398       \n",
      " ayer)                                                           \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,388\n",
      "Trainable params: 2,388\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(2)\n",
    "i, o = encoder.build()\n",
    "model = keras.Model(i, o)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Specified input shape is not one of the valid types. Please specify a batch input shape of type tuple or list of input shapes. User provided input type: <class 'keras.engine.keras_tensor.KerasTensor'>.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [59], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m encoder\u001b[39m.\u001b[39mbuild(i)\n\u001b[1;32m      4\u001b[0m model \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39mModel(Sequential([encoder]))\n\u001b[0;32m----> 5\u001b[0m model\u001b[39m.\u001b[39;49mbuild(i)\n\u001b[1;32m      6\u001b[0m model\u001b[39m.\u001b[39msummary()\n",
      "File \u001b[0;32m~/venv/py3.9/lib/python3.9/site-packages/keras/engine/training.py:435\u001b[0m, in \u001b[0;36mModel.build\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    433\u001b[0m valid_types \u001b[39m=\u001b[39m (\u001b[39mtuple\u001b[39m, \u001b[39mlist\u001b[39m, tf\u001b[39m.\u001b[39mTensorShape, \u001b[39mdict\u001b[39m)\n\u001b[1;32m    434\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(input_shape, valid_types):\n\u001b[0;32m--> 435\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    436\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mSpecified input shape is not one of the valid types. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    437\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPlease specify a batch input shape of type tuple or \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    438\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mlist of input shapes. User provided \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    439\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39minput type: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mtype\u001b[39m(input_shape))\n\u001b[1;32m    440\u001b[0m     )\n\u001b[1;32m    442\u001b[0m \u001b[39mif\u001b[39;00m input_shape \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minputs:\n\u001b[1;32m    443\u001b[0m     \u001b[39m# We create placeholders for the `None`s in the shape and build the\u001b[39;00m\n\u001b[1;32m    444\u001b[0m     \u001b[39m# model in a Graph. Since tf.Variable is compatible with both eager\u001b[39;00m\n\u001b[1;32m    445\u001b[0m     \u001b[39m# execution and graph building, the variables created after building\u001b[39;00m\n\u001b[1;32m    446\u001b[0m     \u001b[39m# the model in a Graph are still valid when executing eagerly.\u001b[39;00m\n\u001b[1;32m    447\u001b[0m     \u001b[39mif\u001b[39;00m tf\u001b[39m.\u001b[39mexecuting_eagerly():\n",
      "\u001b[0;31mValueError\u001b[0m: Specified input shape is not one of the valid types. Please specify a batch input shape of type tuple or list of input shapes. User provided input type: <class 'keras.engine.keras_tensor.KerasTensor'>."
     ]
    }
   ],
   "source": [
    "encoder = EncoderLayer(4,2,2)\n",
    "i = keras.Input(shape=(2,2))\n",
    "encoder.build(i)\n",
    "model = keras.Model(Sequential([encoder]))\n",
    "model.build(i)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 1024, 2) dtype=float32 (created by layer 'encoder_layer_60')>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "time_series.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "5ef3244febf2748b7299853ebe20fbefab2f9f94ffe70cfaeb9efc5b5372c95d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
