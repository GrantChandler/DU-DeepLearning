{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Tensorboard in Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.13.1\n"
     ]
    }
   ],
   "source": [
    "# Import standard libraries that you may use most times\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torchinfo import summary\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "# You should first run this in your enviroment\n",
    "# conda install -c conda-forge tensorboard\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring back MNIST dataset\n",
    "\n",
    "# Convert Pil image to PyTorch Tensor\n",
    "data_transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# Load the data set\n",
    "mnist_train = datasets.MNIST(root='./data', train=True,  transform=data_transform, download=True)\n",
    "mnist_test  = datasets.MNIST(root='./data', train=False, transform=data_transform, download=True)\n",
    "\n",
    "# Prepare dataloaders\n",
    "train_dataloader = torch.utils.data.DataLoader(mnist_train, batch_size=64, shuffle=True)\n",
    "test_dataloader  = torch.utils.data.DataLoader(mnist_test,  batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "NeuralNet                                [1, 10]                   --\n",
       "├─Flatten: 1-1                           [1, 784]                  --\n",
       "├─Linear: 1-2                            [1, 128]                  100,480\n",
       "├─ReLU: 1-3                              [1, 128]                  --\n",
       "├─Dropout: 1-4                           [1, 128]                  --\n",
       "├─Linear: 1-5                            [1, 10]                   1,290\n",
       "├─Softmax: 1-6                           [1, 10]                   --\n",
       "==========================================================================================\n",
       "Total params: 101,770\n",
       "Trainable params: 101,770\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 0.10\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.00\n",
       "Params size (MB): 0.41\n",
       "Estimated Total Size (MB): 0.41\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bring back the MNIST classfier model\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1     = nn.Linear(28 * 28, 128)\n",
    "        self.relu    = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.fc2     = nn.Linear(128, 10)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x) # Flatten tensor\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.softmax(self.fc2(x))\n",
    "        return x\n",
    "    \n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Create model\n",
    "model = NeuralNet().to(device)\n",
    "\n",
    "# Print summary\n",
    "summary(model, input_size=(1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's compare optimizers performance and log them on tensorboard\n",
    "\n",
    "# Loss function\n",
    "CEloos   = nn.CrossEntropyLoss()\n",
    "\n",
    "# Fit the model\n",
    "num_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(epochs, writer, optimizer):\n",
    "    # Iterate over #epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        # Keep track of network progress\n",
    "        train_loss    = 0.0\n",
    "        train_correct = 0\n",
    "        test_correct  = 0\n",
    "\n",
    "        # Visit each data sample once (random)\n",
    "        for image, labels in train_dataloader: \n",
    "            # Compute model prediction and loss\n",
    "            pred_labels = model(image.to(device))\n",
    "            loss        = CEloos(pred_labels, labels.to(device))\n",
    "\n",
    "            # Backpropagate\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()       \n",
    "\n",
    "            # Add loss to history\n",
    "            train_loss    += loss.item()\n",
    "            # Count number of correct predictions \n",
    "            train_correct += (torch.argmax(pred_labels.cpu(), 1) == labels.cpu()).sum().item()\n",
    "\n",
    "        # Test loop (once per epoch)\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_dataloader:\n",
    "                pred_labels = model(images.to(device))\n",
    "                test_correct += (torch.argmax(pred_labels.cpu(), 1) == labels.cpu()).sum().item()\n",
    "\n",
    "        # Compute accuracy (train & test)\n",
    "        train_acc = train_correct / len(mnist_train)\n",
    "        test_acc  = test_correct  / len(mnist_test)\n",
    "        \n",
    "        # Log on Tensroboard using writer\n",
    "        writer.add_scalar(\"Train Acc:\", train_acc, epoch)\n",
    "        writer.add_scalar(\"Test  Acc:\", test_acc, epoch)\n",
    "        writer.add_scalar(\"Loss/train\", train_loss / len(mnist_train), epoch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SummaryWriter instance.\n",
    "# Writer will output to ./runs/ directory by default. \n",
    "writer_adam = SummaryWriter(\"logs/adam\")\n",
    "writer_sgd  = SummaryWriter(\"logs/sgd\")\n",
    "\n",
    "# Train\n",
    "optimizer_adam = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "train_model(num_epochs, writer_adam, optimizer_adam)\n",
    "\n",
    "# IMPORTANT: Flush model! and train again\n",
    "model = NeuralNet().to(device)\n",
    "optimizer_sgd  = torch.optim.SGD(model.parameters(),  lr=0.1)\n",
    "\n",
    "train_model(num_epochs, writer_sgd,  optimizer_sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-f42676cc869a5324\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-f42676cc869a5324\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "\n",
    "%tensorboard --logdir logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* More PyTorch+Tensorboard examples at: https://pytorch.org/docs/stable/tensorboard.html\n",
    "* Tensorboard alternative (highly recommended): https://wandb.ai/site\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "beginner.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "dff0aaeeb8ee9738611fdcb903e0426fbcf38bc2d039ac205716a81cc1909598"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
