{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "XVhK72Pu1cJL"
   },
   "source": [
    "#### Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T02:53:20.699018Z",
     "iopub.status.busy": "2022-12-14T02:53:20.698277Z",
     "iopub.status.idle": "2022-12-14T02:53:23.285398Z",
     "shell.execute_reply": "2022-12-14T02:53:23.284632Z"
    },
    "id": "7rZnJaGTWQw0"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.callbacks  import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Lambda, SimpleRNN, Dense\n",
    "\n",
    "import IPython, IPython.display, os, datetime\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ts_utils\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (14, 4)\n",
    "mpl.rcParams['axes.grid'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "df, df_scaled_trn, df_scaled_tst, scaler = ts_utils.load_file()\n",
    "print(\"Training Data:\")\n",
    "display(df_scaled_trn)\n",
    "\n",
    "input_slice  = slice(0,3)\n",
    "label_slice  = slice(1,3)\n",
    "window_len   = 3\n",
    "ouput_len    = 3\n",
    "batch_size   = 5\n",
    "\n",
    "ouput_feat_len  = label_slice.stop - (label_slice.start or 0)\n",
    "model_op_len    = ouput_feat_len * ouput_len\n",
    "\n",
    "ds_trn = tf.data.Dataset.from_tensor_slices(df_scaled_trn[df_scaled_trn.columns[input_slice]])\n",
    "ds_tst = tf.data.Dataset.from_tensor_slices(df_scaled_tst[df_scaled_trn.columns[input_slice]])\n",
    "window_trn = ts_utils.window(ds_trn, window_len, ouput_len, label_slice, batch_size=batch_size, skip=1)\n",
    "window_tst = ts_utils.window(ds_tst, window_len, ouput_len, label_slice, batch_size=batch_size, skip=1)\n",
    "\n",
    "#print(\"\\n\\nSample Window to verify the window is working:\\n\")\n",
    "#for w in window_trn.take(3):\n",
    "#    print(f\"{w[0].numpy().shape}\\n{w[0].numpy()}\\n=>:{w[1].numpy().shape}\\n{w[1].numpy()} \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yh: [batch, time, features length]\n",
    "def inv_transform(yh, scaler, label_slice):\n",
    "    yy=np.zeros([yh.shape[0], yh.shape[1], scaler.n_features_in_])\n",
    "    yy[:, :, label_slice] = yh[0]\n",
    "    ys = []\n",
    "    for i in range(yh.shape[0]):\n",
    "        yi = scaler.inverse_transform(yy[i])\n",
    "        ys.append(yi[:, label_slice])\n",
    "    return np.stack(ys)\n",
    "    \n",
    "#inv_transform(yh, scaler, label_slice)\n",
    "\n",
    "def predict(model, window_trn, n=1):\n",
    "    for w in window_trn.take(n):\n",
    "        x = w[0]\n",
    "        yh = model.predict(x)\n",
    "        print(x.shape, x, \"\\n\\n\", yh, yh.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_fit(model, window_trn, window_tst= None, opt=None, patience=3, epochs=1):\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=patience, mode='min')\n",
    "\n",
    "    loss = tf.keras.losses.MeanSquaredError()\n",
    "    opt  = opt or tf.keras.optimizers.Adam()\n",
    "    mets = [tf.keras.metrics.MeanAbsoluteError()]\n",
    "\n",
    "    ##=> Other options you can try\n",
    "    #learning_rate = 1e-6\n",
    "    #opt = tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.9)\n",
    "    #opt = tf.keras.optimizers.SGD()\n",
    "    #loss=tf.keras.losses.Huber()\n",
    "\n",
    "    model.compile(loss= loss, optimizer= opt, metrics=mets)\n",
    "\n",
    "    history = []\n",
    "    if (window_trn is not None):\n",
    "        history = model.fit(window_trn, epochs=epochs, validation_data=window_tst, callbacks=[early_stop])\n",
    "\n",
    "    return history\n",
    "\n",
    "# This commonLayer, a layer that is common to all models\n",
    "\n",
    "def getCommonLayer(ouput_len, ouput_feat_len):\n",
    "    op_len = ouput_len * ouput_feat_len;\n",
    "    commonLayer = [\n",
    "        # Shape => [batch, 1, out_len * #features]\n",
    "        tf.keras.layers.Dense( op_len, kernel_initializer=tf.initializers.zeros()),\n",
    "        # Shape => [batch, out_steps, features]\n",
    "        tf.keras.layers.Reshape([ouput_len, ouput_feat_len])\n",
    "    ]\n",
    "    return commonLayer\n",
    "\n",
    "performance = {}\n",
    "models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "srnn_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.SimpleRNN(40)]\n",
    "    + getCommonLayer(ouput_len, ouput_feat_len)\n",
    "    , name=\"SimpleRNN\")\n",
    "\n",
    "models.append(srnn_model)\n",
    "model = srnn_model\n",
    "for opt in \"sgd adam\".split():\n",
    "    history = compile_fit(model, window_trn, window_tst, epochs=5, opt=opt )\n",
    "    performance[model.name + f\":{opt}\"] = ts_utils.eval_performance(model, window_trn, window_tst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T03:02:16.490628Z",
     "iopub.status.busy": "2022-12-14T03:02:16.490367Z",
     "iopub.status.idle": "2022-12-14T03:02:46.815152Z",
     "shell.execute_reply": "2022-12-14T03:02:46.814503Z"
    },
    "id": "kfRz_WVhIQcd"
   },
   "outputs": [],
   "source": [
    "# Linear Model\n",
    "linear_model = tf.keras.Sequential([\n",
    "    # Take the last time-step.\n",
    "    # Shape [batch, time, features] => [batch, 1, features]\n",
    "    tf.keras.layers.Lambda(lambda x: x[:, -1:, :])\n",
    "    ] + getCommonLayer(ouput_len, ouput_feat_len),\n",
    "    name = \"Linear\"\n",
    ")\n",
    "models.append(linear_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a Dense Layer\n",
    "\n",
    "dlinear_model = tf.keras.Sequential([\n",
    "        # Take the last time-step.\n",
    "        # Shape [batch, time, features] => [batch, 1, features]\n",
    "        tf.keras.layers.Lambda(lambda x: x[:, -1:, :]),\n",
    "        tf.keras.layers.Dense(512, activation='relu')\n",
    "    ] +  getCommonLayer(ouput_len, ouput_feat_len),\n",
    "    name = \"DenseLinear\"\n",
    ")\n",
    "\n",
    "models.append(dlinear_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T03:03:43.956741Z",
     "iopub.status.busy": "2022-12-14T03:03:43.956087Z",
     "iopub.status.idle": "2022-12-14T03:04:30.802894Z",
     "shell.execute_reply": "2022-12-14T03:04:30.802236Z"
    },
    "id": "0xJoIP6PMWMI"
   },
   "outputs": [],
   "source": [
    "# CNN\n",
    "CONV_WIDTH = 3\n",
    "conv_model = tf.keras.Sequential([\n",
    "    # Shape [batch, time, features] => [batch, CONV_WIDTH, features]\n",
    "    tf.keras.layers.Lambda(lambda x: x[:, -CONV_WIDTH:, :]),\n",
    "    # Shape => [batch, 1, conv_units]\n",
    "    tf.keras.layers.Conv1D(256, activation='relu', kernel_size=(CONV_WIDTH)),\n",
    "    ] + getCommonLayer(ouput_len, ouput_feat_len),\n",
    "    name = \"Conv\"\n",
    ")\n",
    "models.append(conv_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T03:04:30.807611Z",
     "iopub.status.busy": "2022-12-14T03:04:30.806770Z",
     "iopub.status.idle": "2022-12-14T03:05:37.592821Z",
     "shell.execute_reply": "2022-12-14T03:05:37.592112Z"
    },
    "id": "Bf1ks6RTzF64"
   },
   "outputs": [],
   "source": [
    "# LSTM\n",
    "\n",
    "lstm_model = tf.keras.Sequential([\n",
    "        # Shape [batch, time, features] => [batch, lstm_units].\n",
    "        # Adding more `lstm_units` just overfits more quickly.\n",
    "\n",
    "        tf.keras.layers.LSTM(32, return_sequences=False)\n",
    "    ]+ getCommonLayer(ouput_len, ouput_feat_len),\n",
    "    name = \"LSTM\"\n",
    ")\n",
    "models.append(lstm_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    history = compile_fit(model, window_trn, window_tst, epochs=5 )\n",
    "    performance[model.name] = ts_utils.eval_performance(model, window_trn, window_tst)\n",
    "\n",
    "# Plot graphs\n",
    "performance = ts_utils.plot_performance([], window_trn, window_tst, performance=performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in window_trn:\n",
    "    d, y = w\n",
    "    yh = linear_model.predict(d)\n",
    "    #print( \"=>\\n\\n\", l[0], l[1], d.shape, l.shape)\n",
    "    break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "max_n = 3\n",
    "skip  = 1\n",
    "\n",
    "for i in range(max_n):\n",
    "    di, yi, yhi = d[i], y[i], yh[i]\n",
    "    #plt.subplot(max_n, 1, i+1)\n",
    "    #plt.ylim (-3,3)\n",
    "\n",
    "    #mm = MinMaxScaler()\n",
    "    #di = mm.fit_transform(di)\n",
    "\n",
    "    for j in range(di.shape[1]):\n",
    "        pass\n",
    "        plt.plot(range(di.shape[0]), di[:, j], marker='.', label = \"Inputs\")\n",
    "\n",
    "    for j in range(yi.shape[1]):\n",
    "        xx = range( skip+di.shape[0], skip+di.shape[0]+yi.shape[1]+1)\n",
    "        yy = yi[:,j]\n",
    "        hy = yhi[:,j]\n",
    "        plt.scatter( xx, yy, edgecolors='k', marker='o', label='Labels', c='#2ca02c', s=64)\n",
    "        plt.scatter( xx, hy, edgecolors='k', marker='X', label='Labels', c='#ff7f0e', s=64)\n",
    "\n",
    "    break;\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "time_series.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "dff0aaeeb8ee9738611fdcb903e0426fbcf38bc2d039ac205716a81cc1909598"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
