{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard libraries that you may use most times\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "mpl.rcParams['figure.figsize'] = (16, 5)\n",
    "mpl.rcParams['axes.grid'] = False\n",
    "# -------------------------------------------------------------------------\n",
    "# 1. Some book keeping    \n",
    "print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Dataset.range(10)\n",
    "print([v.numpy() for v in ds])\n",
    "ds1 = ds.window(5, shift=1)\n",
    "print(\"Shift by 1:\", [[v1.numpy() for v1 in v] for v in ds1])\n",
    "\n",
    "ds1 = ds.window(5, shift=1, drop_remainder=True)\n",
    "print(\"Shift by 2:\", [[v1.numpy() for v1 in v] for v in ds1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Dataset.range(10)\n",
    "ds1 = ds.window(5, shift=1, drop_remainder=True)\n",
    "ds1 = ds1.flat_map(lambda w: w.batch(5))\n",
    "for w in ds1:\n",
    "    print(w, w.numpy())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Data for RNN LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_dataset(ds):\n",
    "    for inputs, targets in ds:\n",
    "        print(\"---Batch---\")\n",
    "        print(\"Feature:\", inputs.numpy())\n",
    "        print(\"Label:\", targets.numpy())\n",
    "        print(\"\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window(dataset, label_slice, input_sequence_length, output_sequence_length, batch_size):\n",
    "    ds = dataset.window(input_sequence_length + output_sequence_length, shift=1, drop_remainder=True)\n",
    "    ds = ds.flat_map(lambda x: x).batch(input_sequence_length + output_sequence_length)\n",
    "     \n",
    "    def split_feature_label(x):\n",
    "        return x[:input_sequence_length], x[input_sequence_length:,label_slice]\n",
    "     \n",
    "    ds = ds.map(split_feature_label)\n",
    "     \n",
    "    return ds.batch(batch_size)\n",
    " \n",
    "#ds = tf.data.Dataset.from_tensor_slices(simple_data_samples)\n",
    "#ds = timeseries_dataset_from_dataset(ds, slice(3, None, None), input_sequence_length=4, output_sequence_length=2, batch_size=2)\n",
    "#print_dataset(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = tf.data.Dataset.from_tensor_slices(values)\n",
    "ds = window(ds, slice(3, 5, None), input_sequence_length=4, output_sequence_length=2, batch_size=2)\n",
    "print_dataset(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ds = tf.data.experimental.CsvDataset(\"../data/stockdata.csv\", header=True) #, record_defaults=[5])\n",
    "#ds = ds.map(lambda *items: tf.stack(items))\n",
    "#ds = window(ds, slice(3, None, None), input_sequence_length=4, output_sequence_length=2, batch_size=2)\n",
    "#print_dataset(ds)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '../data/jena_climate_2009_2016.csv.zip'\n",
    "#file = '../data/stockdata.csv'\n",
    "df = pd.read_csv(file)\n",
    "df['Date Time'] = pd.to_datetime( df['Date Time'] )\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testvalues():\n",
    "    values = np.array([\n",
    "         [1, 10, 100,  -1, -1],\n",
    "         [2, 20, 200,  -2, -2],\n",
    "         [3, 30, 300,  -3, -3],\n",
    "         [4, 40, 400,  -4, -4],\n",
    "         [5, 50, 500,  -5, -5],\n",
    "         [6, 60, 600,  -6, -6],\n",
    "         [7, 70, 700,  -7, -7],\n",
    "         [8, 80, 800,  -8, -8],\n",
    "         [9, 90, 900,  -9, -9],\n",
    "         [10,100,1000, -10, -10],\n",
    "         [11,110,1100, -11, -11],\n",
    "         [12,120,1200, -12, -12],\n",
    "    ])\n",
    "    return values;\n",
    "\n",
    "def print_test(ds, len=4):\n",
    "    for inputs, targets in ds:\n",
    "        print(inputs.numpy() , targets.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_len = 5\n",
    "fcast_len  = 2\n",
    "batch_size = 2\n",
    "\n",
    "#values = df.values[:, 1:5]\n",
    "values = testvalues()\n",
    "dataset = tf.data.Dataset.from_tensor_slices(values)\n",
    "dataset = dataset.window(window_len + fcast_len, shift=1, drop_remainder=True)\n",
    "dataset = dataset.flat_map(lambda x: x).batch(window_len + fcast_len)\n",
    "\n",
    "def split_feature_label(x):\n",
    "    return x[:window_len], x[window_len:,fcast_len]\n",
    "     \n",
    "dataset = dataset.map(split_feature_label)\n",
    "dataset.batch(batch_size)\n",
    "print_test(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vv=np.array([\n",
    " [ 1 , 1 , 1 ,-1 , -1],\n",
    " [ 2 , 2 , 2 ,-2 , -2],\n",
    " [ 3 , 3 , 3 ,-3 , -3],\n",
    " [ 4 , 4 , 4 ,-4 , -4],\n",
    " [ 5 , 5 , 5 ,-5 , -5],\n",
    " [ 6 , 6 , 6 ,-6 , -6],\n",
    " [ 7 , 7 , 7 ,-7 , -7]])\n",
    "\n",
    "vv = values\n",
    "vv[:5], vv[5:7,2:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = testvalues()\n",
    "dataset = tf.data.Dataset.from_tensor_slices(values)\n",
    "dataset = dataset.window(window_len + fcast_len, shift=1, drop_remainder=True)\n",
    "dataset = dataset.flat_map(lambda x: x).batch(window_len + fcast_len)\n",
    "for w in (dataset):\n",
    "    print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time series generator Example:\n",
    "\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "dftt = pd.read_csv(\"\");\n",
    "gen = TimeseriesGenerator(dftt.values,dftt.values, length =window_len, batch_size = batch_size)\n",
    "print(\"========================\")\n",
    "for g in gen:\n",
    "    print(g[1])\n",
    "    break;\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "beginner.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  5 2022, 01:53:17) \n[Clang 12.0.0 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
